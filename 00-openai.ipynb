{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer des requêtes simples vers un modèle de langage (LLM) via l’API OpenAI\n",
    "\n",
    "Installation des dépendences, pour le moment seul le wrapper de l'api openai est suffisant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du client OpenAI (attention à ne pas commiter ou partager la clé :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "load_dotenv()\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création de la requête\n",
    "\n",
    "* temperature - entre 0 et 1. Une valeur haute, comme 0.8 entraînera une complétion plus aléatoire. Alors qu'une valeur faible, comme 0.2 donnera une complétion plus déterminste\n",
    "* messages - La liste des messages de la conversation\n",
    "* max_completion_tokens - Permet de limiter le nombre de token de la complétion, pour pouvoir par exemple contrôler le coût de la génération.\n",
    "\n",
    "[==> API reference](https://platform.openai.com/docs/api-reference/chat/create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explique moi la théorie de la relativité en termes simples\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La complétion (réponse) du modèle est accessible dans l'objet sous le chemin `choices[0].message.content`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(chat_completion.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cas pratique :\n",
    "\n",
    "1. Créer des requêtes simples vers un modèle de langage (LLM) via l’API.\n",
    "2. Analyser les résultats générés en fonction des prompts et comprendre comment le modèle traite l'information.\n",
    "3. Expérimenter différents types de prompts pour explorer les capacités du modèle et voir comment les réponses varient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1 : Prompts descriptifs\n",
    "Envoyez un prompt pour obtenir une explication simple d'un concept technique.\n",
    "prompt = \"Explique-moi le fonctionnement d'un moteur à combustion interne.\"\n",
    "\n",
    "### Exercice 2: Questions ouvertes vs fermées\n",
    "Posez des questions ouvertes et des questions fermées pour voir comment le modèle réagit.\n",
    "prompt = \"Quels sont les défis actuels du changement climatique ?\"\n",
    "prompt = \"Le changement climatique affecte-t-il la montée du niveau de la mer ?\"\n",
    "\n",
    "### Exercice 3: Génération créative\n",
    "Essayez de jouer avec la température (ex. 0.3 vs 0.9) et observez les différences :\n",
    "prompt = \"En 3 phrases, rRaconte une courte histoire où un robot devient ami avec un humain.\"\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
