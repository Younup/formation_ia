{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à Langchain \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dépendances et clé d'API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Décommenter sur Google Colab\n",
    "#%pip install langchain langchain-openai langchain_mistralai openai python-dotenv -q\n",
    "#from google.colab import userdata\n",
    "#api_key=userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "#Décommenter en local\n",
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "load_dotenv()\n",
    "api_key= getenv(\"OPENAI_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla via api OpenAI\n",
    "\n",
    "Sortez les rames :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today in Paris, the weather is clear with a temperature of 20°C. It sounds like a lovely day to explore the city!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from openai.types.responses import ResponseFunctionToolCall\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def initial_llm_request(user_message: str):\n",
    "    \"\"\"\n",
    "    Make the initial request to the LLM with the user's message.\n",
    "    \"\"\"\n",
    "    tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get current temperature for a given location.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"City and country e.g. Bogotá, Colombia\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"location\"\n",
    "        ],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}]\n",
    "    return client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=[{\"role\": \"user\", \"content\": user_message}],\n",
    "        tools=tools\n",
    "    )\n",
    "\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Simulate a weather API call.\n",
    "    In a real-world scenario, you would replace this with an actual API call to a weather service.\n",
    "    \"\"\"\n",
    "    # Simulated response\n",
    "    return f\"The current temperature in {location} is 20°C with clear skies.\"\n",
    "\n",
    "\n",
    "\n",
    "def handle_tool_call(response):\n",
    "    \"\"\"\n",
    "    Handle the tool call response from the LLM.\n",
    "    If the response contains a tool call, execute it and return the result.\n",
    "    \"\"\"\n",
    "    if isinstance(response.output[0], ResponseFunctionToolCall):\n",
    "        tool_call = response.output[0]\n",
    "        if tool_call.name == \"get_weather\":\n",
    "            import json\n",
    "            tool_args = json.loads(tool_call.arguments)\n",
    "            location = tool_args.get(\"location\", \"\")\n",
    "            weather = get_weather(location)\n",
    "            return weather\n",
    "    return None\n",
    "\n",
    "\n",
    "def final_llm_call(user_message: str, weather_info: str):\n",
    "    \"\"\"\n",
    "    Make a final call to the LLM with the weather information.\n",
    "    \"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=[{\"role\": \"user\", \"content\": user_message}, {\"role\": \"developer\", \"content\": weather_info}],\n",
    "    )\n",
    "\n",
    "    return response.output_text\n",
    "\n",
    "\n",
    "\n",
    "user_message = \"What is the weather like in Paris today?\"\n",
    "initial_response = initial_llm_request(user_message)\n",
    "weather_info = handle_tool_call(initial_response)\n",
    "if weather_info:\n",
    "    final_response = final_llm_call(user_message, weather_info)\n",
    "    print(final_response)\n",
    "else:\n",
    "    print(\"No tool call was made by the LLM.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Tools et toolkits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nme: youtube_search\n",
      "Description: search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional\n",
      "Args: {'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.utilities import OpenWeatherMapAPIWrapper\n",
    "\n",
    "os.environ[\"OPENWEATHERMAP_API_KEY\"] = \"\"\n",
    "\n",
    "weather = OpenWeatherMapAPIWrapper()\n",
    "weather_data = weather.run(\"London,GB\")\n",
    "print(weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"OPENWEATHERMAP_API_KEY\"] = \"\"\n",
    "\n",
    "tools = [weather.run]\n",
    "agent = create_react_agent(\"openai:gpt-4.1-mini\", tools)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
